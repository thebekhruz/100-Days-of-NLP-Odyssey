{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal:\n",
    "### Score = Semantic Similarity + λ × Contextual Relevance\n",
    "\n",
    "This section will attempt to calculate the contextual relevance of named entities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # Load the small English model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IAID</th>\n",
       "      <th>text</th>\n",
       "      <th>mentions</th>\n",
       "      <th>relations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a7bb9917-95ff-3f55-a640-4c5afcec25f2</td>\n",
       "      <td>View towards SE of junction of Queen Victoria ...</td>\n",
       "      <td>[{'ne_span': 'Queen Victoria Road', 'ne_start'...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c29a7b77-7c46-3b85-88fe-05c8f4b2e384</td>\n",
       "      <td>Front page of Bucks Free Press, Time capsule f...</td>\n",
       "      <td>[{'ne_span': 'Bucks Free Press', 'ne_start': 1...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196c11e6-f7b6-392f-ae41-28653345087c</td>\n",
       "      <td>High Wycombe Police Station, in Queen Victoria...</td>\n",
       "      <td>[{'ne_span': 'High Wycombe Police Station', 'n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7a5aace6-2398-3dcf-8843-37ff6ccea875</td>\n",
       "      <td>Reference Library door, Queen Victoria Rd, Hig...</td>\n",
       "      <td>[{'ne_span': 'Reference Library', 'ne_start': ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c66c4715-c03a-3aab-964b-e733f3ff1cf4</td>\n",
       "      <td>Terrace of brick and flint cottages, Beech Rd,...</td>\n",
       "      <td>[{'ne_span': 'Beech Rd', 'ne_start': 37, 'ne_e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d1159b13-8aa9-35c1-a4c2-fd13e24732b2</td>\n",
       "      <td>Site of former Dial House, demolition at corne...</td>\n",
       "      <td>[{'ne_span': 'Dial House', 'ne_start': 15, 'ne...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e39a291d-ed39-3b56-b9aa-2022964a4114</td>\n",
       "      <td>Row of cottages and part of factory building, ...</td>\n",
       "      <td>[{'ne_span': 'Coopers Yard', 'ne_start': 46, '...</td>\n",
       "      <td>[{'subject': 'https://www.wikidata.org/wiki/Q6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3b84ea4c-e194-3c34-abbf-064a41ad59da</td>\n",
       "      <td>60th anniversary of opening of Library, part o...</td>\n",
       "      <td>[{'ne_span': 'Library', 'ne_start': 31, 'ne_en...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bf418a27-d1d9-324b-a53f-50ab7ae8d81d</td>\n",
       "      <td>View towards NE of crossroads at junction of Q...</td>\n",
       "      <td>[{'ne_span': 'Queen Victoria Rd', 'ne_start': ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5bc83263-dcd0-3764-98cb-a3761480b4c7</td>\n",
       "      <td>High Wycombe Police Station, Queen Victoria Ro...</td>\n",
       "      <td>[{'ne_span': 'High Wycombe Police Station', 'n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   IAID  \\\n",
       "0  a7bb9917-95ff-3f55-a640-4c5afcec25f2   \n",
       "1  c29a7b77-7c46-3b85-88fe-05c8f4b2e384   \n",
       "2  196c11e6-f7b6-392f-ae41-28653345087c   \n",
       "3  7a5aace6-2398-3dcf-8843-37ff6ccea875   \n",
       "4  c66c4715-c03a-3aab-964b-e733f3ff1cf4   \n",
       "5  d1159b13-8aa9-35c1-a4c2-fd13e24732b2   \n",
       "6  e39a291d-ed39-3b56-b9aa-2022964a4114   \n",
       "7  3b84ea4c-e194-3c34-abbf-064a41ad59da   \n",
       "8  bf418a27-d1d9-324b-a53f-50ab7ae8d81d   \n",
       "9  5bc83263-dcd0-3764-98cb-a3761480b4c7   \n",
       "\n",
       "                                                text  \\\n",
       "0  View towards SE of junction of Queen Victoria ...   \n",
       "1  Front page of Bucks Free Press, Time capsule f...   \n",
       "2  High Wycombe Police Station, in Queen Victoria...   \n",
       "3  Reference Library door, Queen Victoria Rd, Hig...   \n",
       "4  Terrace of brick and flint cottages, Beech Rd,...   \n",
       "5  Site of former Dial House, demolition at corne...   \n",
       "6  Row of cottages and part of factory building, ...   \n",
       "7  60th anniversary of opening of Library, part o...   \n",
       "8  View towards NE of crossroads at junction of Q...   \n",
       "9  High Wycombe Police Station, Queen Victoria Ro...   \n",
       "\n",
       "                                            mentions  \\\n",
       "0  [{'ne_span': 'Queen Victoria Road', 'ne_start'...   \n",
       "1  [{'ne_span': 'Bucks Free Press', 'ne_start': 1...   \n",
       "2  [{'ne_span': 'High Wycombe Police Station', 'n...   \n",
       "3  [{'ne_span': 'Reference Library', 'ne_start': ...   \n",
       "4  [{'ne_span': 'Beech Rd', 'ne_start': 37, 'ne_e...   \n",
       "5  [{'ne_span': 'Dial House', 'ne_start': 15, 'ne...   \n",
       "6  [{'ne_span': 'Coopers Yard', 'ne_start': 46, '...   \n",
       "7  [{'ne_span': 'Library', 'ne_start': 31, 'ne_en...   \n",
       "8  [{'ne_span': 'Queen Victoria Rd', 'ne_start': ...   \n",
       "9  [{'ne_span': 'High Wycombe Police Station', 'n...   \n",
       "\n",
       "                                           relations  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6  [{'subject': 'https://www.wikidata.org/wiki/Q6...  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_path = '/Users/thebekhruz/Desktop/100Days-Of-Code/100-Days-of-NLP-Odyssey/data/raw/data_formatted_date.jsonl'\n",
    "df = pd.read_json(input_file_path, lines=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete relations column as it does not have any meaningful information\n",
    "del df['relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN mentions rows where removed.\n"
     ]
    }
   ],
   "source": [
    "# Check and remove rows with empty 'mentions' dictionaries\n",
    "if df['mentions'].isnull().sum()>0:\n",
    "    df = df.dropna(subset=['mentions'])\n",
    "    print('NaN mentions rows where removed.')\n",
    "else:\n",
    "    print('There are no empty mentions dictionaries in the database')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract specific keys from dictionaries in the 'mentions' column and create a new column\n",
    "def extract_key_from_dict_list(dict_list, key):\n",
    "    if isinstance(dict_list, list):\n",
    "        result = [element.get(key) for element in dict_list if isinstance(element, dict) and key in element]\n",
    "        return result\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IAID</th>\n",
       "      <th>text</th>\n",
       "      <th>mentions</th>\n",
       "      <th>extracted_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a7bb9917-95ff-3f55-a640-4c5afcec25f2</td>\n",
       "      <td>View towards SE of junction of Queen Victoria ...</td>\n",
       "      <td>[{'ne_span': 'Queen Victoria Road', 'ne_start'...</td>\n",
       "      <td>[Queen Victoria Road, High St, Easton St, High...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c29a7b77-7c46-3b85-88fe-05c8f4b2e384</td>\n",
       "      <td>Front page of Bucks Free Press, Time capsule f...</td>\n",
       "      <td>[{'ne_span': 'Bucks Free Press', 'ne_start': 1...</td>\n",
       "      <td>[Bucks Free Press, Clock House, Arts School, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196c11e6-f7b6-392f-ae41-28653345087c</td>\n",
       "      <td>High Wycombe Police Station, in Queen Victoria...</td>\n",
       "      <td>[{'ne_span': 'High Wycombe Police Station', 'n...</td>\n",
       "      <td>[High Wycombe Police Station, Queen Victoria R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7a5aace6-2398-3dcf-8843-37ff6ccea875</td>\n",
       "      <td>Reference Library door, Queen Victoria Rd, Hig...</td>\n",
       "      <td>[{'ne_span': 'Reference Library', 'ne_start': ...</td>\n",
       "      <td>[Reference Library, Queen Victoria Rd, High Wy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c66c4715-c03a-3aab-964b-e733f3ff1cf4</td>\n",
       "      <td>Terrace of brick and flint cottages, Beech Rd,...</td>\n",
       "      <td>[{'ne_span': 'Beech Rd', 'ne_start': 37, 'ne_e...</td>\n",
       "      <td>[Beech Rd, Wycombe Marsh, 1935]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   IAID  \\\n",
       "0  a7bb9917-95ff-3f55-a640-4c5afcec25f2   \n",
       "1  c29a7b77-7c46-3b85-88fe-05c8f4b2e384   \n",
       "2  196c11e6-f7b6-392f-ae41-28653345087c   \n",
       "3  7a5aace6-2398-3dcf-8843-37ff6ccea875   \n",
       "4  c66c4715-c03a-3aab-964b-e733f3ff1cf4   \n",
       "\n",
       "                                                text  \\\n",
       "0  View towards SE of junction of Queen Victoria ...   \n",
       "1  Front page of Bucks Free Press, Time capsule f...   \n",
       "2  High Wycombe Police Station, in Queen Victoria...   \n",
       "3  Reference Library door, Queen Victoria Rd, Hig...   \n",
       "4  Terrace of brick and flint cottages, Beech Rd,...   \n",
       "\n",
       "                                            mentions  \\\n",
       "0  [{'ne_span': 'Queen Victoria Road', 'ne_start'...   \n",
       "1  [{'ne_span': 'Bucks Free Press', 'ne_start': 1...   \n",
       "2  [{'ne_span': 'High Wycombe Police Station', 'n...   \n",
       "3  [{'ne_span': 'Reference Library', 'ne_start': ...   \n",
       "4  [{'ne_span': 'Beech Rd', 'ne_start': 37, 'ne_e...   \n",
       "\n",
       "                                  extracted_entities  \n",
       "0  [Queen Victoria Road, High St, Easton St, High...  \n",
       "1  [Bucks Free Press, Clock House, Arts School, F...  \n",
       "2  [High Wycombe Police Station, Queen Victoria R...  \n",
       "3  [Reference Library, Queen Victoria Rd, High Wy...  \n",
       "4                    [Beech Rd, Wycombe Marsh, 1935]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# This function applies the extraction of a key for a series in a DataFrame\n",
    "def apply_extraction_to_column(df, column_name, key, new_column_name):\n",
    "    df[new_column_name] = df[column_name].apply(lambda x: extract_key_from_dict_list(x, key))\n",
    "    return df\n",
    "\n",
    "\n",
    "df = apply_extraction_to_column(df, 'mentions', 'ne_span', 'extracted_entities')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF analysis\n",
    "1. Clean data / Preprocessing — Clean data (standardise data) , Normalize data( all lower case) , lemmatize data ( all words to root words ).\n",
    "2. Tokenize words with frequency\n",
    "3. Find TF for words\n",
    "4. Find IDF for words\n",
    "5. Vectorize vocab\n",
    "\n",
    "source: https://medium.com/analytics-vidhya/tf-idf-term-frequency-technique-easiest-explanation-for-text-classification-in-nlp-with-code-8ca3912e58c3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesses the given text by removing punctuation, making text lowercase, and removing stop words.\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- * If you want to calculate the TF-IDF scores for all the words in your preprocessed text, then you should use preprocessed_text.\n",
    "* If you are specifically interested in the TF-IDF scores for the named entities (i.e., ne_span) only, then you should use preprocessed_entities. -->\n",
    "\n",
    "$ Score = Semantic Similarity * *w* * Contextual Relevance (TF-IDF) $\n",
    "#### Significance of Named Entities Within Documents:\n",
    "* To prioritize named entities in documents, focus on *preprocessed_entities* for TF-IDF calculations. This emphasizes entity importance independently of surrounding text.\n",
    "#### Semantic Similarity and Contextual Relevance:\n",
    "* TF-IDF fine-tunes the $Score$ by giving more importance to specific named entities. Using *preprocessed_entities* provides a focused relevance score on the entities without diluting the effect sorounding text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocess_text function on the text and exctracted_entities column\n",
    "# Uncomment this if you think that contextual information is important\n",
    "    # df['preprocessed_text'] = df['text'].apply(preprocess_text)\n",
    "df['preprocessed_entities'] = df['extracted_entities'].apply(lambda x: [preprocess_text(entity) for entity in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>02173</th>\n",
       "      <th>02174</th>\n",
       "      <th>02181</th>\n",
       "      <th>02183</th>\n",
       "      <th>02184</th>\n",
       "      <th>02212</th>\n",
       "      <th>1230</th>\n",
       "      <th>13</th>\n",
       "      <th>13th</th>\n",
       "      <th>13thc</th>\n",
       "      <th>...</th>\n",
       "      <th>yard</th>\n",
       "      <th>ye</th>\n",
       "      <th>ymca</th>\n",
       "      <th>yorkshire</th>\n",
       "      <th>youers</th>\n",
       "      <th>young</th>\n",
       "      <th>youngs</th>\n",
       "      <th>ypres</th>\n",
       "      <th>zager</th>\n",
       "      <th>zephaniah</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IAID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a7bb9917-95ff-3f55-a640-4c5afcec25f2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c29a7b77-7c46-3b85-88fe-05c8f4b2e384</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196c11e6-f7b6-392f-ae41-28653345087c</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7a5aace6-2398-3dcf-8843-37ff6ccea875</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c66c4715-c03a-3aab-964b-e733f3ff1cf4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2323 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      02173  02174  02181  02183  02184  \\\n",
       "IAID                                                                      \n",
       "a7bb9917-95ff-3f55-a640-4c5afcec25f2    0.0    0.0    0.0    0.0    0.0   \n",
       "c29a7b77-7c46-3b85-88fe-05c8f4b2e384    0.0    0.0    0.0    0.0    0.0   \n",
       "196c11e6-f7b6-392f-ae41-28653345087c    0.0    0.0    0.0    0.0    0.0   \n",
       "7a5aace6-2398-3dcf-8843-37ff6ccea875    0.0    0.0    0.0    0.0    0.0   \n",
       "c66c4715-c03a-3aab-964b-e733f3ff1cf4    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "                                      02212  1230   13  13th  13thc  ...  \\\n",
       "IAID                                                                 ...   \n",
       "a7bb9917-95ff-3f55-a640-4c5afcec25f2    0.0   0.0  0.0   0.0    0.0  ...   \n",
       "c29a7b77-7c46-3b85-88fe-05c8f4b2e384    0.0   0.0  0.0   0.0    0.0  ...   \n",
       "196c11e6-f7b6-392f-ae41-28653345087c    0.0   0.0  0.0   0.0    0.0  ...   \n",
       "7a5aace6-2398-3dcf-8843-37ff6ccea875    0.0   0.0  0.0   0.0    0.0  ...   \n",
       "c66c4715-c03a-3aab-964b-e733f3ff1cf4    0.0   0.0  0.0   0.0    0.0  ...   \n",
       "\n",
       "                                      yard   ye  ymca  yorkshire  youers  \\\n",
       "IAID                                                                       \n",
       "a7bb9917-95ff-3f55-a640-4c5afcec25f2   0.0  0.0   0.0        0.0     0.0   \n",
       "c29a7b77-7c46-3b85-88fe-05c8f4b2e384   0.0  0.0   0.0        0.0     0.0   \n",
       "196c11e6-f7b6-392f-ae41-28653345087c   0.0  0.0   0.0        0.0     0.0   \n",
       "7a5aace6-2398-3dcf-8843-37ff6ccea875   0.0  0.0   0.0        0.0     0.0   \n",
       "c66c4715-c03a-3aab-964b-e733f3ff1cf4   0.0  0.0   0.0        0.0     0.0   \n",
       "\n",
       "                                      young  youngs  ypres  zager  zephaniah  \n",
       "IAID                                                                          \n",
       "a7bb9917-95ff-3f55-a640-4c5afcec25f2    0.0     0.0    0.0    0.0        0.0  \n",
       "c29a7b77-7c46-3b85-88fe-05c8f4b2e384    0.0     0.0    0.0    0.0        0.0  \n",
       "196c11e6-f7b6-392f-ae41-28653345087c    0.0     0.0    0.0    0.0        0.0  \n",
       "7a5aace6-2398-3dcf-8843-37ff6ccea875    0.0     0.0    0.0    0.0        0.0  \n",
       "c66c4715-c03a-3aab-964b-e733f3ff1cf4    0.0     0.0    0.0    0.0        0.0  \n",
       "\n",
       "[5 rows x 2323 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all arrays to create a single list of preprocessed entities across all documents\n",
    "all_entities = sum(df['preprocessed_entities'], [])\n",
    "\n",
    "# Convert this list into a string where each entity is separated by a space (to simulate a \"document\" of entities)\n",
    "entities_text = ' '.join(all_entities)\n",
    "\n",
    "# Create a \"document\" for each set of entities in each row to calculate TF-IDF scores\n",
    "entities_documents = [' '.join(entities) for entities in df['preprocessed_entities']]\n",
    "\n",
    "# Initialize the vectorizer\n",
    "entity_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the entities documents to calculate TF-IDF\n",
    "entity_tfidf_matrix = entity_vectorizer.fit_transform(entities_documents)\n",
    "\n",
    "# tfidf_df = pd.DataFrame(entity_tfidf_matrix.toarray(), columns=entity_vectorizer.get_feature_names_out())\n",
    "tfidf_df = pd.DataFrame(entity_tfidf_matrix.toarray(), index=df['IAID'], columns=entity_vectorizer.get_feature_names_out())\n",
    "tfidf_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ne_span': 'Queen Victoria Road',\n",
       " 'ne_start': 31,\n",
       " 'ne_end': 50,\n",
       " 'ne_type': 'LOC',\n",
       " 'total_tfidf_score': 0.902690796523274}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to get the TF-IDF score for a word in a specific document using IAID\n",
    "def get_tfidf_score(word, vectorizer, tfidf_df, iaid):\n",
    "    index = vectorizer.vocabulary_.get(word)\n",
    "    # If the word is in the vocabulary, return its score for the specific document based on IAID\n",
    "    if index is not None:\n",
    "        return tfidf_df.loc[iaid, vectorizer.get_feature_names_out()[index]]\n",
    "    else:\n",
    "        # If the word is not in the vocabulary, return 0\n",
    "        return 0\n",
    "\n",
    "# Function to calculate the total TF-IDF score for each mention's ne_span for a specific document using IAID\n",
    "def add_tfidf_scores_to_mentions(row, vectorizer, tfidf_df):\n",
    "    mentions = row['mentions']\n",
    "    iaid = row['IAID']  # Use IAID to reference the document in tfidf_df\n",
    "    for mention in mentions:\n",
    "        words = mention['ne_span'].lower().split()\n",
    "        # Note: Ensure that `preprocess_text` is applied here if necessary, as per your preprocessing logic\n",
    "        total_score = sum(get_tfidf_score(word, vectorizer, tfidf_df, iaid) for word in words)\n",
    "        mention['total_tfidf_score'] = total_score\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "df.apply(lambda row: add_tfidf_scores_to_mentions(row, entity_vectorizer, tfidf_df), axis=1)\n",
    "df['mentions'][0][0]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")  # Load the small English model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame loaded as df\n"
     ]
    }
   ],
   "source": [
    "# Load data \n",
    "input_file_path = '/Users/thebekhruz/Desktop/100Days-Of-Code/100-Days-of-NLP-Odyssey/data/processed/data_with_contextual_relevance_and_doc_embddings.jsonl'\n",
    "\n",
    "try:\n",
    "    df = pd.read_json(input_file_path, lines=True)\n",
    "    print('Data Frame loaded as df')\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $Score = Semantic Similarity + λ × Contextual Relevance$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Universal Preprocessing step\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")  # Load the small English model\n",
    "def extract_named_entities_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    named_entities = [ent.label_ for ent in doc.ents if ent.label_ in ['DATE', 'LOC', 'PERSON', 'ORG', 'MISC']]\n",
    "\n",
    "    return named_entities\n",
    "\n",
    "# Example usage\n",
    "# query = \"What is Queen Victoria Road in High Wycombe known for?\"\n",
    "query = \"What historical events took place at Queen Victoria Road in High Wycombe?\"\n",
    "\n",
    "named_entities = extract_named_entities_spacy(query)\n",
    "print(named_entities)\n",
    "# search(query, model, k=5, weight=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "bert_model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LOC', 'LOC']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "def extract_named_entities_bert(text):\n",
    "    # Create a pipeline for named entity recognition\n",
    "    nlp = pipeline(\"ner\", model=bert_model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "    # Process the text\n",
    "    ner_results = nlp(text)\n",
    "\n",
    "    # Now, ner_results will include aggregated entities with 'word' and 'entity_group' keys\n",
    "    entities_with_spans = [ ent['entity_group'] for ent in ner_results]\n",
    "\n",
    "    return entities_with_spans\n",
    "\n",
    "# Example usage\n",
    "query = \"What historical events took place at Queen Victoria Road in High Wycombe?\"\n",
    "named_entities_with_spans = extract_named_entities_bert(query)\n",
    "print(named_entities_with_spans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# # Given entities look for documents that have those entities and then exctract total_tfidf_scores\n",
    "# def get_tf_idf_score(doc_index, named_entities):\n",
    "#     # Search in mentions if document has the given entities type\n",
    "#     for i in range(len(df.iloc[doc_index]['mentions'])):\n",
    "#         if df.iloc[doc_index]['mentions'][i]['ne_span'] in named_entities:\n",
    "#             return df.iloc[doc_index]['mentions'][i]['total_tfidf_score']\n",
    "\n",
    "# print(get_tf_idf_score(1, ['DATE', 'PERSON']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tfidf score for document 1: 4.3981177834\n"
     ]
    }
   ],
   "source": [
    "# Get tfidf score by entity type\n",
    "def get_tf_idf_score(doc_index, named_entities_types):\n",
    "    # Accesses the mentions column for doc_index\n",
    "    mentions = df.iloc[doc_index]['mentions']\n",
    "    # Filter mentions to only include those with the named entity types\n",
    "    relevant_mentions = [mention for mention in mentions if mention['ne_type'] in named_entities_types]\n",
    "    # Sum the tfidf scores for the relevant mentions\n",
    "    total_score = sum([mention['total_tfidf_score'] for mention in relevant_mentions])\n",
    "    # print(f\"Total tfidf score for document {doc_index}: {total_score}\")\n",
    "    return total_score\n",
    "\n",
    "# Test the function\n",
    "get_tf_idf_score(1, ['ORG', 'PER'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tfidf score by entity type\n",
    "def get_tfidf_score(doc_index, named_entities_types):\n",
    "    # Accesses the mentions column for doc_index\n",
    "    mentions = df.iloc[doc_index]['mentions']\n",
    "    # Filter mentions to only include those with the named entity types\n",
    "    relevant_mentions = [mention for mention in mentions if mention['ne_type'] in named_entities_types]\n",
    "    # Sum the tfidf scores for the relevant mentions\n",
    "    total_score = sum([mention['total_tfidf_score'] for mention in relevant_mentions])\n",
    "    # print(f\"Total tfidf score for document {doc_index}: {total_score}\")\n",
    "    return total_score\n",
    "\n",
    "def search(query, model, k=5, weight=10):\n",
    "\n",
    "    # Extract named entity types from the query\n",
    "    # print(f\"Query: {query}\")\n",
    "    named_entity_types = extract_named_entities_bert(query)\n",
    "\n",
    "    # Preprocess and encode the query\n",
    "    query = preprocess_text(query)\n",
    "    query_embedding = model.encode([query])\n",
    "\n",
    "    # Calculate semantic similarity\n",
    "    semantic_similarity = cosine_similarity(query_embedding, np.array(df['text_embedding'].tolist())).flatten()\n",
    "    top_k_indices = np.argsort(semantic_similarity)[-k:][::-1]\n",
    "\n",
    "    \n",
    "    # Initialize a list to store final documents with their computed scores\n",
    "    final_scores = []\n",
    "\n",
    "    for index in top_k_indices:\n",
    "        # Calculate TF-IDF score based on matching named entity types\n",
    "        # print(f\"Document {index}:\")\n",
    "        # print('Named entity types:', named_entity_types)\n",
    "        tf_idf_score = get_tfidf_score(index, named_entity_types)\n",
    "        # print('TF-IDF score:', tf_idf_score)\n",
    "\n",
    "        final_score = semantic_similarity[index] + weight * tf_idf_score\n",
    "        final_scores.append((index, final_score))\n",
    "\n",
    "    # Sort documents by their final score in descending order\n",
    "    final_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print the most similar documents\n",
    "    for i in range(len(final_scores)):\n",
    "        print(f\"Document Rank {i+1}:\")\n",
    "        print(df.iloc[final_scores[i][0]]['text'])\n",
    "        print(f\"Final score: {final_scores[i][1]}\")\n",
    "        print(\"---\")\n",
    "    \n",
    "    # Return the top k documents based on their final scores\n",
    "    # return [df.iloc[index] for index, score in final_scores[:k]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"msmarco-distilbert-dot-v5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many employees does Google have?\"\n",
    "search(query, model, k=5, weight=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "High Wycombe Police Station and Town Hall Queen Victoria Road, High Wycombe. late 1935\n",
      "Police Station and Town Hall viewed side on and commemorative bridge over River Wye on western side\n",
      "Final score: 440.007296244417\n",
      "---\n",
      "Document 2:\n",
      "High Wycombe Police Station, Queen Victoria Road, High Wycombe about 1935\n",
      "New Police Station High Wycombe\n",
      "Final score: 433.2550713145417\n",
      "---\n",
      "Document 3:\n",
      "High Wycombe Police Station, in Queen Victoria Road, High Wycombe. Oct 1935\n",
      "New Police Station High Wycombe viewed from opposite side of the road\n",
      "Final score: 418.3740381641876\n",
      "---\n",
      "Document 4:\n",
      "Queen Victoria Rd under construction, High Wycombe, about 1901\n",
      "Construction of Queen Victoria Rd north of R. Wye\n",
      "Final score: 329.20085051290584\n",
      "---\n",
      "Document 5:\n",
      "New Police Station in Queen Victoria Road, High Wycombe in 1937\n",
      "New Police Station High Wycombe\n",
      "Final score: 228.8259715284566\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# General Query about a Location: \n",
    "query = \"What is Queen Victoria Road in High Wycombe known for?\"\n",
    "search(query, model, k=5, weight=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "High Wycombe Police Station, Queen Victoria Road, High Wycombe about 1935\n",
      "New Police Station High Wycombe\n",
      "Final score: 433.1705213127112\n",
      "---\n",
      "Document 2:\n",
      "View of S. side of Wycombe Abbey School, High Wycombe, date unknown\n",
      "View of Wycombe Abbey School showing cloisters on S. side\n",
      "Final score: 73.59741819301809\n",
      "---\n",
      "Document 3:\n",
      "Postcard showing a view of the entrance hall Wycombe Abbey School, High Wycombe. date unknown\n",
      "Interior of Wycombe Abbey School, entrance hall with American Plaque, Gothic style window and ceiling, table chairs and carpet, picture/hanging over fireplace\n",
      "Final score: 28.803922330703692\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Specific Event or Item Query: \n",
    "query = \"Information about the time capsule found in High Wycombe.\"\n",
    "search(query, model, k=3, weight=100)\n",
    "# The model does not perform that well for specific events. When considering only Semanticity and not contextual relevance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Reference Library door, Queen Victoria Rd, High Wycombe. about 1992\n",
      "Corridor entrance to Reference Library\n",
      "Final score: 269.64036306412777\n",
      "---\n",
      "Document 2:\n",
      "Reference Library, Queen Victoria Rd, High Wycombe. 1993 to 1994\n",
      "Reference Library\n",
      "Final score: 179.83889007235686\n",
      "---\n",
      "Document 3:\n",
      "Two Library staff in the Reference Library, Queen Victoria Rd, High Wycombe. about 1992\n",
      "Reference Library\n",
      "Final score: 152.23178482965233\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Cultural or Historical Site Query: \n",
    "query = \"Where is the Reference Library located in High Wycombe?\"\n",
    "search(query, model, k=3, weight=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "High Wycombe Police Station, Queen Victoria Road, High Wycombe about 1935\n",
      "New Police Station High Wycombe\n",
      "Final score: 433.20799750655937\n",
      "---\n",
      "Document 2:\n",
      "Looking N, a view of the front of Wycombe Museum (formerly Castle Hill House), with two benches against the wall. Priory Ave, High Wycombe. early 1990's\n",
      "Front of Wycombe Museum, formerly Castle Hill House, with two benches against the wall The drive runs along the right.\n",
      "Final score: 397.08873355325073\n",
      "---\n",
      "Document 3:\n",
      "Looking SE, a view of the N front of Wycombe Abbey from the drive, Abbey Grounds, High Wycombe. Circa 1895\n",
      "The North front of Wycombe Abbey, from the drive\n",
      "Final score: 95.95599441603447\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Broad Historical or Cultural Query:\n",
    "query = \"Historical landmarks in High Wycombe.\"\n",
    "search(query, model, k=3, weight=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Many guests dining at an Official reception shortly after the opening of the new Town Hall, Queen Victoria Rd, High Wycombe. Nov 1904\n",
      "Interior Town Hall\n",
      "Final score: 0.8590923183311419\n",
      "---\n",
      "Document 2:\n",
      "Opening ceremony of the Library, Queen Victoria Rd. High Wycombe, 25 June 1932\n",
      "Outside new Library\n",
      "Final score: 0.8535580246911669\n",
      "---\n",
      "Document 3:\n",
      "High Wycombe Police Station and Town Hall Queen Victoria Road, High Wycombe. late 1935\n",
      "Police Station and Town Hall viewed side on and commemorative bridge over River Wye on western side\n",
      "Final score: 0.8445607071278922\n",
      "---\n",
      "Document 4:\n",
      "High Wycombe Police Station, Queen Victoria Road, High Wycombe about 1935\n",
      "New Police Station High Wycombe\n",
      "Final score: 0.8426387084822465\n",
      "---\n",
      "Document 5:\n",
      "Queen Victoria Rd under construction, High Wycombe, about 1901\n",
      "Construction of Queen Victoria Rd north of R. Wye\n",
      "Final score: 0.8400235361005131\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "query = \"Are there any annual cultural festivities taking place at Queen Victoria Road, High Wycombe?\"\n",
    "search(query, model, k=5, weight=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
